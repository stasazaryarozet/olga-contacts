# АНАЛИЗ: Задача нерешаема при текущих ограничениях?

**Дата:** 2025-11-01  
**Статус:** Критическая оценка выполнимости

---

## ОГРАНИЧЕНИЯ (подтверждены)

```yaml
budget: 0 рублей (критично)
quality: confidence ≥ 0.85 (желаемо)
google_cloud: не используется (критично)
local_llm_hardware: 16GB RAM, Intel i7, 4GB GPU
effort: → 0 (автономность)
```

---

## ОЦЕНКА ОТ GEMINI

### Локальная LLM на данном железе:
- **Модель:** Llama 3.1 8B (Q5_K_M)
- **Качество:** confidence ~0.50-0.65
- **Время:** 1.5 часа на 20 документов
- **Нагрузка:** Полная загрузка CPU/RAM
- **Вердикт:** ❌ Качество неприемлемо для задачи

### Google Gemini 1.5 Flash API:
- **Качество:** confidence ~0.90-0.95
- **Бюджет:** 0 (free tier: 1500 req/day)
- **Вердикт:** ✅ Идеально, но Google Cloud не используется

---

## АЛЬТЕРНАТИВНЫЕ БЕСПЛАТНЫЕ API

### 1. Groq API
- **Модели:** Llama 3.1 70B, Mixtral 8x7B
- **Free tier:** Существует (ограничен)
- **Качество NER/RE (русский):** Неизвестно, но 70B >> 8B
- **Статус:** Нужно проверить

### 2. Anthropic Claude (Haiku)
- **Free tier:** НЕТ (только платный)
- **Вердикт:** ❌ Не подходит

### 3. Hugging Face Inference API
- **Модели:** Различные (некоторые бесплатны)
- **Качество:** Зависит от модели
- **Rate limits:** Строгие
- **Статус:** Сомнительно

### 4. Together AI / Fireworks AI
- **Free tiers:** Ограниченные
- **Качество:** Неизвестно
- **Статус:** Нужно проверить

---

## ВОПРОС К ТЕБЕ

При ограничениях **Budget = 0** + **Без Google** + **Качество ≥ 0.85**, есть три варианта:

### Вариант A: Другие бесплатные API
Проверить:
- Groq API (Llama 3.1 70B)
- Together AI / Fireworks AI
- Другие?

**Вопрос:** Приемлемы ли другие cloud providers (не Google)?

### Вариант B: Принять низкое качество
Использовать Llama 3.1 8B локально:
- Качество: confidence ~0.60 (много ошибок)
- Бюджет: 0
- Автономность: полная

**Вопрос:** Приемлем ли график "грязный, но бесплатный"?

### Вариант C: Гибридный подход
Rule-based extraction (regex + heuristics) + минимальные API calls для disambiguation:
- Основная работа: regex (бесплатно, быстро, confidence ~0.50)
- Сложные случаи: API call (если найдём бесплатный)

**Вопрос:** Имеет ли смысл такой компромисс?

### Вариант D: Отложить проект
Честно признать: **задача нерешаема** при данных ограничениях.
Подождать до момента, когда:
- Появится бюджет ($50-150/мес)
- ИЛИ улучшится железо (больше RAM/GPU)
- ИЛИ появятся бесплатные качественные API

---

## МОЯ РЕКОМЕНДАЦИЯ

Нужно выбрать один из путей:

1. **Разрешить другие бесплатные APIs** (Groq, и т.д.) → Я проверю их качество
2. **Принять confidence ~0.60** с локальной LLM → Я реализую с Ollama
3. **Отложить проект** до изменения ограничений

Какой путь выбираем?

