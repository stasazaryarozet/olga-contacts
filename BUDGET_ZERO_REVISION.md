# КРИТИЧЕСКАЯ КОРРЕКТИРОВКА: Бюджет = 0

**Дата:** 2025-11-01  
**Проблема:** Вся архитектура спроектирована для budget $50-150/month. Требование: **0 рублей**.

---

## ЧТО НЕПРИМЕНИМО

### Из TASK_SOW.md:
- ❌ Claude 3.5 Sonnet API ($45/month)
- ❌ AWS Lambda + SQS + S3 (~$5/month)
- ❌ Neo4j Aura Professional ($65/month)
- ❌ Google Custom Search API (100 запросов/день бесплатно, но ограничено)

**Total rejected cost:** $115/month minimum

---

## НОВЫЕ ОГРАНИЧЕНИЯ

```yaml
budget: 0 рублей
effort: → 0 (по-прежнему)
quality: ??? (нужно определить trade-off)
```

---

## ВОПРОСЫ ДЛЯ ПЕРЕPРОЕКТИРОВАНИЯ

### 1. LLM Strategy

**Проблема:** Claude API стоит денег. Локальный LLM бесплатен, но:
- Требует GPU/мощный компьютер (у координатора есть?)
- Качество NER/RE значительно ниже Claude 3.5
- Gemini сказал: "quantized Llama 3.1 8B confidence > 0.95 **недостижим**"

**Варианты:**
- A) Ollama + Llama 3.1 8B (бесплатно, качество низкое)
- B) Ollama + Mixtral 8x7B (бесплатно, качество средне-низкое)
- C) Отказаться от LLM, использовать rule-based + regex (бесплатно, качество очень низкое)

**Вопрос:** Приемлем ли trade-off: бюджет 0 → качество extractio значительно ниже?

### 2. Infrastructure Strategy

**Проблема:** AWS Lambda стоит денег (даже если мало).

**Варианты:**
- A) Локальный Python скрипт + cron (бесплатно)
- B) Docker на локальной машине (бесплатно)
- C) Google Colab с периодическим запуском (бесплатно, но не автономно полностью)

**Вопрос:** Где будет работать система? На компьютере координатора 24/7?

### 3. Storage Strategy

**Проблема:** Neo4j Aura Free Tier существует (50k nodes), но:
- Требует internet connection постоянно
- Могут закрыть free tier в будущем

**Варианты:**
- A) SQLite (бесплатно, локально)
- B) JSON files (бесплатно, локально, но не graph queries)
- C) Neo4j Desktop (бесплатно, локально, полноценный граф)

**Вопрос:** Критичны ли graph queries, или достаточно simple SQL/JSON?

### 4. Search Strategy (для Snowballing)

**Проблема:** Google Custom Search API — 100 запросов/день бесплатно, потом платно.

**Варианты:**
- A) Scrapy + прямой search (бесплатно, но anti-bot риск, нарушает Effort → 0)
- B) Отказаться от Snowballing в MVP (бесплатно, граф останется маленьким)
- C) SearXNG (self-hosted meta-search, бесплатно, но сложно)

---

## ПРЕДВАРИТЕЛЬНАЯ НОВАЯ АРХИТЕКТУРА (Budget = 0)

```
Локальный компьютер координатора:
  ├─ Python script (постоянно работает)
  ├─ Ollama + Llama 3.1 8B (локальный LLM)
  ├─ SQLite (storage)
  ├─ Cron/schedule (auto-run раз в день)
  └─ Seed URLs → Fetch → IE → ER → SQLite
```

**Trade-offs:**
- ✅ Бюджет: 0 рублей
- ✅ Автономность: Да (после setup)
- ❌ Качество NER/RE: **Значительно ниже** (confidence 0.7-0.8 вместо 0.95+)
- ❌ Масштабируемость: Зависит от мощности локального компьютера
- ❌ Отказоустойчивость: Если компьютер выключен → система не работает

---

## КРИТИЧЕСКИЙ ВОПРОС

**Приемлема ли формулировка:**
> "Система автономна и бесплатна, но качество извлечения данных ниже, чем при использовании SOTA API"?

Или цель — **максимальное качество при любом бюджете**?

---

## СЛЕДУЮЩИЙ ШАГ

Жду подтверждения:
1. Бюджет = 0 **критичнее** качества?
2. У координатора есть компьютер, который может работать 24/7?
3. Приемлемо ли качество локального LLM (confidence 0.7-0.8)?

После ответа — создам новую архитектуру и новое TASK_SOW.

